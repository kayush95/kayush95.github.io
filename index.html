<!DOCTYPE html>
<!-- <html lang="en"> -->

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Kumar Ayush</title>

    <!-- Bootstrap Core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="css/freelancer.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- <link rel="icon" href="img/icon.jpg"> -->
    <link rel="icon" href="https://www.adobe.com/favicon.ico">
    <script type="text/javascript" src="https://platform.linkedin.com/badges/js/profile.js" async defer></script>
	<style>
		<!---img {
			display: block;
			margin: 0 auto;
			} --->
		#img-circle {
				border-radius: 50px;
				border: 2px solid #73AD21;
			}
		
	</style>
</head>

<body id="page-top" class="index">

    <!-- Navigation -->
    <nav id="mainNav" class="navbar navbar-default navbar-fixed-top navbar-custom">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span> Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand" href="#page-top"> </span> <i class="fa fa-terminal" style="color:black"></i> Kumar Ayush</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li class="page-scroll">
                        <a href="#biography">About</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#experience">Experience</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#publications">Publications</a>
                    </li> 
					<li class="page-scroll">
                        <a href="#patents">Patents</a>
                    </li> 
                    <li class="page-scroll">
                        <a href="#projects">Projects</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#favourites">Favourites</a>
                    </li>					
                    <li class="page-scroll">
                        <a href="https://scholar.google.com/citations?user=gIlnMF8AAAAJ" target="_blank">Google Scholar</a>
                    </li>
                    <li class="page-scroll">
                        <a href="./pdfs/CV.pdf" target="_blank">CV</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#contact">Contact</a>
                    </li>                                                                          
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <img class="img-responsive;img-circle;" src="img/myimage.jpg" style="width:300px; border: 5px solid #FFFFFF;border-radius: 50%;" alt="">
                    <div class="intro-text">
                        <span class="name" >Kumar Ayush</span>
                        <hr class="star-light">
                        <span class="skills"><i class="fa fa-code" style="color:yellow"></i> Machine Learning <i class="fa fa-code" style="color:yellow"></i> Computer Vision <i class="fa fa-code" style="color:yellow"></i> Augmented Reality<i class="fa fa-code" style="color:yellow"></i></span>

                    </div>
                </div>
            </div>
            <div class="col-lg-8 col-lg-offset-2 text-center">
                <p><br><br>I’m Kumar Ayush. I work at Adobe India as a Senior Member of Technical Staff in the Media and Data Science Research Group.
                <!-- I’m Kumar Ayush, a senior undergraduate student at the <a href="http://iitkgp.ac.in/" style="color:cyan">Indian Institute of Technology, Kharagpur</a>. -->
                </p>
                <br></br>
            </div>
           <br></br><br></br><br></br><br></br><br></br>
           <div>
				<!-- <img src="img/new.png" style="width:50px;" align="left"><br><br><br> -->
				<!-- <p style="text-align:justify">Our work, <a href = "#projects" style="color:cyan">OCR++</a>, has been selected for the prestigious <a href="http://gyti.techpedia.in/" target="_blank" style="color:cyan">Gandhian Young Technological Innovation (GYTI) Award 2017</a>. The Gandhian Young Technological Innovation Awards were given at the Festival of Innovations (FOIN), hosted by the office of the <b>President of India</b>, <b>Rashtrapati Bhavan, New Delhi</b>.</p> -->


				<p style="text-align:justify">
				<marquee direction="left" scrolldelay="45" height="50px">

				Paper accepted in <i style="color:cyan">IEEE ICIP 2018</i>.&nbsp;&nbsp;&nbsp;Paper accepted in <i style="color:cyan">IEEE LCN 2017</i>.&nbsp;&nbsp;&nbsp;Poster accepted for publication in <i style="color:cyan">IEEE ISMAR 2017</i>.&nbsp;&nbsp;&nbsp;Received <i style="color:cyan">Best B.Tech Project Award</i> in the Department of Computer Science and Engineering.&nbsp;&nbsp;&nbsp;Paper accepted for publication in <i style="color:cyan">CVPR-2017 Workshop - Computer Vision for Microscopy Image Analysis</i>.
               <!--  &nbsp;&nbsp;&nbsp;Paper accepted for publication in the <i style="color:cyan">IEEE Transactions on Image Processing (TIP)</i> journal.&nbsp;&nbsp;&nbsp;  -->

				</marquee>
				</p>
            </div>			
			

<!---
            <div class="column">
                <div class="col-lg-5 col-lg-offset-0" style="text-align:justify">
                    <p></p>
                </div>
                <div class="col-lg-5 col-lg-offset-2" style="text-align:justify">
                    <p></p>
                </div>
            </div>
--->
        </div>

    </header>

    <!--- Portfolio Grid Section -->
    <section  id="biography">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>About</h2>
                    <hr class="star-primary">
                </div>
            </div>
            <div class="col-lg-10 col-lg-offset-1 text-center" style="text-align:justify">
                <!-- <p style="font-size:19px;">My interests are centered around Deep Learning and its applications in Computer Vision, Natural Language Processing and their intersection. In particular, I am interested in conglomerating deep learning representations with generative modeling, inference in generative models and fully end-to-end learning with neural network architectures. I am also drawn to tackling the major challenges in deep learning, which are unsupervised learning in the regime of small data, and simulation-based learning and its transferability to real world. I have worked with <a href="https://scholar.google.co.in/citations?user=5bXSZPYAAAAJ&hl=en" target="_blank" style="color:rgb(173, 45, 3)">Prof. Pabitra Mitra</a> for my Bachelor's thesis on <i>Generative Adversarial Learning for Reducing Manual Annotation in Semantic Segmentation on Large Scale Microscopy Images</i>. 
                </p> -->
                <p style="font-size:19px;">My interests are centered around Machine Learning and Computer Vision and their applications in Digital Marketing and Augmented Reality. I am also drawn to tackling the major challenges in machine learning, which are unsupervised learning in the regime of small data, and simulation-based learning and its transferability to real world. I have worked with <a href="https://scholar.google.co.in/citations?user=5bXSZPYAAAAJ&hl=en" target="_blank" style="color:rgb(173, 45, 3)">Prof. Pabitra Mitra</a> for my Bachelor's thesis on <i>Generative Adversarial Learning for Reducing Manual Annotation in Semantic Segmentation on Large Scale Microscopy Images</i> and <i>Content Based Video Retrieval</i>. 
                </p>
                <!-- <p>
                A part of my thesis also focused on Semi-Supervised Learning with Generative Adversarial Networks (GANs) for action recognition in images. In future, I wish to work on developing advanced AI technologies for real-world healthcare settings.  
                </p> -->
				<p style="font-size:19px;">I was a research intern (Summer 2016) at the <a href="https://research.adobe.com/about-the-labs/bigdata-experience-lab/" target="_blank" style="color:rgb(173, 45, 3)">Big Data Experience Lab</a> at <a href="https://research.adobe.com/people/#location" target="_blank" style="color:rgb(173, 45, 3)">Adobe Research, Bangalore</a>, working with <a href="https://research.adobe.com/person/gaurush-hiranandani/" target="_blank" style="color:rgb(173, 45, 3)">Gaurush Hiranandani</a> and <a href="https://research.adobe.com/person/atanu-sinha/" target="_blank" style="color:rgb(173, 45, 3)">Dr. Atanu Sinha</a> on <i>Enhanced Digital Marketing using Augmented Reality</i>. Prior to this (Summer 2015), I was a visiting student researcher at <a href="http://val.serc.iisc.ernet.in/valweb/index.html" target="_blank" style="color:rgb(173, 45, 3)">Video Analytics Lab</a>, <a href="http://www.iisc.ac.in/" target="_blank" style="color:rgb(173, 45, 3)">Indian Institute of Science, Bangalore</a>, working with <a href="https://www.linkedin.com/in/srinivaskss" target="_blank" style="color:rgb(173, 45, 3)">Srinivas S. S. Kruthiventi</a>, supervised by <a href="http://www.serc.iisc.ernet.in/~venky/" target="_blank" style="color:rgb(173, 45, 3)">Prof. R. Venkatesh Babu</a>, on <i>Saliency Prediction</i> (<a href="#projects" style="color:rgb(173, 45, 3)">DeepFix</a>).</p> 
				<p style="font-size:19px;">At my undergraduate college, I have been fortunate to work with a variety of faculty on interesting projects. I have worked with <a href="http://cse.iitkgp.ac.in/~sandipc/" target="_blank" style="color:rgb(173, 45, 3)">Prof. Sandip Chakraborty</a> on <i>Supporting Throughput Fairness in IEEE 802.11ac Dynamic Bandwidth Channel Access</i>. Prior to this, I have worked with <a href="http://cse.iitkgp.ac.in/~pawang/" target="_blank" style="color:rgb(173, 45, 3)">Prof. Pawan Goyal</a> on applying conditional random fields to extract information from scholarly articles (<a href="http://www.cnergres.iitkgp.ac.in/OCR++/home/" target="_blank" style="color:rgb(173, 45, 3)">OCR++</a>).
				<br>
                </p>  
                <p><i><b>Internship advice</b>: I'm happy to collaborate with enthusiastic and talented advanced undergraduate students in computer science, electrical engineering or mathematics. I am looking to hire interns to work with me in Noida during summer 2019. Intern slots are limited and competitive. To apply, e-mail me your CV, and a brief description of what you would like to work on during your internship.</p></i>             
            </div>
         </div>
    </section>

    <section class="success" id="experience">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Experience</h2>
                    <hr class="star-light">
                </div>
            </div>

            <div class="row">
                <div align="center">
                    <a href="http://kayush95.github.io" target="_blank" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
        	            <img class="img-circle"  src="img/portfolio/adobe.png" class="img-responsive" style="width:280px;" alt="" hspace="40">
                    </a>
                    <div class="col-lg-15 text-center" >
                		<p><br>Media and Data Science Research<br>Adobe Inc.</p>
            		</div>
                </div>
            </div>

            
            <div class="row">
                <div class="col-sm-4 portfolio-item">
                    <a href="https://research.adobe.com/about-the-labs/bigdata-experience-lab/" target="_blank" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
        	            <img class="img-circle"  src="img/portfolio/adobe.png" class="img-responsive" style="width:280px;" alt="" hspace="40">
                    </a>
                    <div class="col-lg-15 text-center" >
                		<p><br>Big Data Experience Lab<br>Adobe Research</p>
            		</div>
                </div>
                <div class="col-sm-4 portfolio-item">
                    <a href="http://www.iisc.ac.in/" target="_blank" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/iisc.png" class="img-responsive" style="width:280px;" alt="" hspace="40">
                    </a>
                    <div class="col-lg-15 text-center">
                		<p><br>Video Analytics Lab<br>Indian Institute of Science</p>
            		</div>
                </div>
                <div class="col-sm-4 portfolio-item">
                    <a href="http://www.cnergres.iitkgp.ac.in/" target="_blank" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img class="img-circle" src="img/portfolio/cnerg.jpg" class="img-responsive" style="width:280px;" alt="" hspace="40">
                    </a>
                    <div class="col-lg-15 text-center">
                		<p><br>Complex Networks Research Group<br>IIT Kharagpur</p>
            		</div>
                </div>
            </div>
        </div>
    </section>


<!---    <section  id="education">
        <div class="container-fluid">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Education</h2>
                    <hr class="star-primary">
                </div>
            </div>
            <div class="column">
                <div class="col-lg-5 col-lg-offset-2" style="text-align:justify">
                    <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Undergraduate</h3><p><i class="glyphicon glyphicon-education" ></i>&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://iitkgp.ac.in/" target="_blank" style="color:rgb(173, 45, 3)">Indian Institute of Technology, Kharagpur </a> <i>(2013-2017)</i><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B.Tech (Hons.) in <a href="http://cse.iitkgp.ac.in/" target="_blank" style="color:rgb(173, 45, 3)">Computer Science and Engineering</a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cumulative Grade Point Average: <b>9.49/10</b></p>
                </div> 
                <div class="col-lg-5 col-lg-offset-0" style="text-align:justify">
                     <h3>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;High School</h3><p><i class="fa fa-book" ></i>&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://www.srisankaraschools.org/seniorsecondary/" target="_blank" style="color:rgb(173, 45, 3)">Rajendra Vidyalaya, Jamshedpur</a> <i>(2013)</i><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Indian School Certificate (ISC)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CISCE Class XII: <b>97.6%</b></p> 
                </div>
            </div>
         </div>
    </section> --->
	
	
	    <section id="publications">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Publications</h2>
                    <hr class="star-primary">
                </div>
            </div>
            <div class="col-lg-12" style="text-align:justify">
            	<p>[1] <b>Kumar Ayush</b><sup>*</sup>, Abhishek Sinha<sup>*</sup>. <b>"Towards Mathematical Reasoning:  A Multimodal Deep LearningApproach."</b> <i>25th IEEE IEEE International Conference on Image Processing (ICIP).</i> 2018. (Poster, <img src="img/adobe.png"> <a href="https://ieeexplore.ieee.org/document/8451353" target="_blank" style="color:blue">link</a>)</p>

                <p>[2] <b>Kumar Ayush</b>, Raja Karamakar, Varun Rawal, Pradyumna K. Bishoyi, Samiran Chattopadhya, Sandip Chakraborty. <b>"Supporting Throughput Fairness in IEEE 802.11ac Dynamic Bandwidth Channel Access: A Hybrid Approach."</b> <i>42nd IEEE Conference on Local Computer Networks (LCN).</i> 2017. (Oral paper, <img src="img/adobe.png"> <a href="http://ieeexplore.ieee.org/document/8109388/" target="_blank" style="color:blue">link</a>)</p>

                <p>[3] Gaurush Hiranandani, <b>Kumar Ayush</b>, Atanu Sinha, Sai Varun Reddy Maram, Chinnaobireddy Varsha, Pranav Maneriker. <b>"Enhanced Personalized Targeting using Augmented Reality."</b> <i>16th IEEE International Symposium on Mixed and Augmented Reality (ISMAR).</i> 2017. (Poster, <img src="img/adobe.png"> <a href="http://ieeexplore.ieee.org/abstract/document/8088451/" target="_blank" style="color:blue">link</a>)</p>

                <p>[4] Avisek Lahiri, <b>Kumar Ayush</b>, Prabir Biswas, Pabitra Mitra. <b>"Generative Adversarial Learning for Reducing Manual Annotation in Semantic Segmentation on Large Scale Microscopy Images: Automated Vessel Segmentation in Retinal Fundus Image as Test Case."</b> <i>Computer Vision for Microscopy Image Analysis (CVMI) Workshop - Computer Vision and Pattern Recognition (CVPR).</i> 2017. (Workshop, <a href="http://openaccess.thecvf.com/content_cvpr_2017_workshops/w8/papers/Lahiri_Generative_Adversarial_Learning_CVPR_2017_paper.pdf" target="_blank" style="color:blue">link</a>)</p>

                <p>[5] Srinivas S. S. Kruthiventi, <b>Kumar Ayush</b>, R. Venkatesh Babu. <b>"DeepFix: A Fully Convolutional Neural Network for predicting Human Eye Fixations."</b> <i>IEEE Transactions on Image Processing.</i> 2017. (Journal, <img src="img/adobe.png"> <a href="http://ieeexplore.ieee.org/document/7937829/" target="_blank" style="color:blue">link</a>)</p>

                <p>[6] Mayank Singh, Barnopriyo Barua, Priyank Palod, Manvi Garg, Sidhartha Satapathy, Samuel Bushi, <b>Kumar Ayush</b>, Krishna Sai Rohith, Tulasi Gamidi, Pawan Goyal, Animesh Mukherjee. <b>"OCR++: A Robust Framework For Information Extraction from Scholarly Articles."</b> <i>26th International Conference on Computational Linguistics (Coling).</i> 2016. (Poster, <img src="img/adobe.png" alt=""><a href="https://www.aclweb.org/anthology/C/C16/C16-1320.pdf" target="_blank" style="color:blue">link</a>, <a href="http://www.cnergres.iitkgp.ac.in/OCR++/home/" target="_blank" style="color:blue">framework</a>)</p>

                <sup>*</sup><i>Denotes Equal Contribution</i>
            </div>     
        </div>
    </section>
	
	<section id="patents">
	<div class="container">
		<div class="row">
			<div class="col-lg-12 text-center">
				<h2>Patents</h2>
				<hr class="star-primary">
			</div>
		</div>
        <div class="col-lg-12" style="text-align:justify">
            <p>[1] <b>Kumar Ayush</b>, Atanu R Sinha, Gaurush Hiranandani. <b>"Augmented Viewpoint Driven Bundle Recommendation in Virtual Commerce."</b> (Under Review by Adobe Patent Review Committee)</p>

            <p>[2] <b>Kumar Ayush</b>, Gaurush Hiranandani, Atanu R Sinha. <b>"Compatibility Energy based Identification of Incompatible Products in Augmented Reality Viewpoint."</b> (In filing process)
            
            <p>[3] <b>Kumar  Ayush</b>,  Harsh  Vardhan  Chopra. <b>"Context Aware Background Scene and 3D Object Compatibility for Creation of Photorealistic 3D Images."</b> (In filing process)
            
            <p>[4] <b>Kumar Ayush</b>, Gaurush Hiranandani. <b>"Augmented Reality Based Style Aware Recommendations Based on Perceptual Shape Style Compatibility with Objects in the Viewpoint."</b> <i>US 15/972,815</i>. (Filed)
            
            <p>[5] <b>Kumar Ayush</b>, Gaurush Hiranandani. <b>"Generating and Providing Augmented Reality Representations of Recommended Products Based on Style Similarity in Relation to Real-World Surroundings."</b> <i>US 16/004,787</i>. (Filed)

            <p>[6] Gaurush Hiranandani, <b>Kumar Ayush</b>, Sai Varun Maram Reddy, Chinnaobireddy Varsha, Siddhant Jain.  <b>"Creating Personalized Catalogues with Recommendations Embedded in Augmented Viewpoint to Retarget Consumers."</b> <i>US62/415,332</i>. (Filed)

            <p>[7] Gaurush Hiranandani, <b>Kumar Ayush</b>, Chinnaobireddy Varsha, Sai Varun Maram Reddy. <b>"Creating Targeted Content based on Detected Characteristics of an Augmented Reality Scene."</b> <i>US 15/454,750</i>. (<a href="https://patents.google.com/patent/US20180260843A1/en" target="_blank" style="color:blue">Published</a>)</p>

            <p>[8] Gaurush Hiranandani, Sai Varun Maram Reddy, <b>Kumar Ayush</b>, Chinnaobireddy Varsha, Siddhant Jain. <b>"Product Recommendations Based on Augmented Reality Viewpoints."</b> <i>US 15/492,971, DE 102017007998.6, AU 2017216603,GB 1714133.4, CN 201710780770.6</i>. (<a href="https://patents.google.com/patent/US20180121988A1/en" target="_blank" style="color:blue">Published</a>)</p>
            <p>[9] Gaurush Hiranandani, Chinnaobireddy Varsha, Sai Varun Maram Reddy, <b>Kumar Ayush</b>, Atanu R Sinha. <b>"Identifying Augmented Reality Visuals Influencing User Behavior in Virtual-Commerce Environments."</b> <i>US 15/433, 834</i>. (<a href="https://patents.google.com/patent/US20180232952A1/en" target="_blank" style="color:blue">Published</a>)</p>
		</div>     
	</div>
	</section>

    <!--- Portfolio Grid Section -->
    <section class="success" id="projects">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Projects</h2>
                    <hr class="star-light">
                </div>
            </div>
            <div class="row">
                <div class="col-sm-4 portfolio-item">
                    <a href="#proj3" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/ikea.jpg" class="img-responsive" style="width:400px;height:250px;border: 3px solid #FFFFFF;border-radius: 95%;" alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                        <p><br>Enhanced Digital Marketing using Augmented Reality</p>
                    </div>
                </div>
                <div class="col-sm-4 portfolio-item">
                    <a href="#proj5" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/difs_pifs.png" class="img-responsive" style="width:400px;height:250px;border: 3px solid #FFFFFF;border-radius: 95%;" alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                        <p><br>Supporting Throughput Fairness in IEEE 802.11ac Dynamic Bandwidth Channel Access: A Hybrid Approach</p>
                    </div>                
                </div>
                <div class="col-sm-4 portfolio-item">
                    <a href="#proj2" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/ocr++.PNG" class="img-responsive" style="width:400px;height:250px;border: 3px solid #FFFFFF;border-radius: 95%;" alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                		<p><br>OCR++: A Robust Framework For Information Extraction from Scholarly Articles</p>
            		</div>
                </div>
            </div>
            <div class="row">  
                <div class="col-sm-4 portfolio-item">
                    <a href="#proj1" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/sal.PNG" class="img-responsive" style="width:400px;height:250px;border: 3px solid #FFFFFF;border-radius: 95%;" alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                        <p><br>DeepFix: A Fully Convolutional Neural Network for predicting Human Eye Fixations</p>
                    </div>
                </div>
                <!-- <div class="col-sm-4 portfolio-item">
                    <a href="#proj4" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/seg.png" class="img-responsive" style="width:400px;height:250px;border: 3px solid #FFFFFF;border-radius: 95%;" alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                		<p><br>Combining Class Conditioned Representations in CNN for Salient Object Segmentation</p>
            		</div>                    
                </div> -->
                <div class="col-sm-4 portfolio-item">
                    <a href="#proj8" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/retina.jpg" class="img-responsive" style="width:1200px;height:250px;border-radius: 95%;" alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                        <p><br>Generative Adversarial Learning for Reducing Manual Annotation in Semantic Segmentation on Large Scale Microscopy Images</p>
                    </div>
                </div>
                <div class="col-sm-4 portfolio-item">
                    <a href="#proj6" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/other.jpg" class="img-responsive" style="width:400px;height:250px;border: 3px solid #FFFFFF;border-radius: 95%;" alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                		<p><br>Other Projects</p>
            		</div>                      
                </div>
            </div>
        </div>

        <br>
        <!-- <hr class="star-light">

        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h3 >Bachelor's Thesis</h3>
                </div>
            </div>
            <div class="row" style="padding-left:290px;padding-right:0px;">

                <div class="col-sm-4 portfolio-item">
                    <a href="#proj8" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/retina.jpg" class="img-responsive" style="width:1200px;height:250px;border-radius: 15px;" alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                        <p><br>Generative Adversarial Learning for Reducing Manual Annotation in Semantic Segmentation on Large Scale Microscopy Images</p>
                    </div>
                </div>

                <div class="col-sm-4 portfolio-item">
                    <a href="#proj7" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/action.png" class="img-responsive" style="width:1200px;height:250px;border-radius: 15px;" alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                        <p><br>Semi-Supervised Learning with Generative Adversarial Networks for Action Recognition in Images</p>
                    </div>
                </div>

            </div>
        </div>         -->
    </section>



    <section class="" id="favourites">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Favourites</h2>
                    <hr class="star-primary">
                </div>
			</div>
				
            <div class="row">
                <div class="col-sm-4 portfolio-item">
                    <a href="http://www.paulgraham.com/articles.html" class="portfolio-link" data-toggle="modal" target="_blank">
                        <div class="caption">
                            <div class="caption-content">
                                
                            </div>
                        </div>
                        <img src="img/portfolio/paulgraham.jpg" class="img-responsive" style="width:400px;height:300px;border: 5px solid #FFFFFF;border-radius: 75%;"  alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                		<p><br>Paul Graham's Essays</p>
            		</div>
                </div>
				
                <div class="col-sm-4 portfolio-item">
                    <a href="https://www.ycombinator.com/" class="portfolio-link" data-toggle="modal" target="_blank">
                        <div class="caption">
                            <div class="caption-content">
                                
                            </div>
                        </div>
                        <img src="img/portfolio/y.png" class="img-responsive" style="width:400px;height:300px;border: 5px solid #FFFFFF;border-radius: 75%;"" alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                		<p><br>Y Combinator</p>
            		</div>
                </div>


                <div class="col-sm-4 portfolio-item">
                    <a href="https://blog.openai.com/" class="portfolio-link" data-toggle="modal" target="_blank">
                        <div class="caption">
                            <div class="caption-content">
                                
                            </div>
                        </div>
                        <img src="img/portfolio/openai.png" class="img-responsive" style="width:400px;height:300px;border: 5px solid #FFFFFF;border-radius: 75%;"" alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                		<p><br>OpenAI's Blog</p>
            		</div>
				</div>
               <!--  <br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br> -->

<!--                 <div class="col-sm-4 portfolio-item">
                    <a href="http://colah.github.io/" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                
                            </div>
                        </div>
                        <img src="img/portfolio/colah.jpg" class="img-responsive" style="width:400px;height:300px;border: 5px solid #FFFFFF;border-radius: 75%;"" alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                		<p><br>Christopher Olah's Blog</p>
            		</div>
                </div>

               

                <div class="col-sm-4 portfolio-item">
                    <a href="http://www.pyimagesearch.com/" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                
                            </div>
                        </div>
                        <img src="img/portfolio/adrianrosebrock.jpg" class="img-responsive" style="width:800px;height:300px;border: 5px solid #FFFFFF;border-radius: 75%;"" alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                		<p><br>PyImageSearch by Adrian Rosebrock</p>
            		</div>                    
                </div>
                <div class="col-sm-4 portfolio-item">
                    <a href="https://www.stumbleupon.com/" class="portfolio-link" data-toggle="modal">
                        <div class="caption">
                            <div class="caption-content">
                                
                            </div>
                        </div>
                        <img src="img/portfolio/stumble.png" class="img-responsive" style="width:400px;height:300px;border: 5px solid #FFFFFF;border-radius: 75%;"" alt="">
                    </a>
                    <div class="col-lg-15 text-center" >
                		<p><br>StumbleUpon</p>
            		</div>                    
                </div>	 -->			
               
            </div>        
        </div>
    </section>

    <!-- Contact Section -->
    <section class="success" id="contact">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Contact Me</h2>
                    <hr class="star-light">

                </div>
            </div>
            <div class="column">
                <div class="col-lg-4 col-lg-offset-0">
					
                    <br></br><br></br>
<!-- 					<span style="font-size:1.5em;">Email:</span>
					<span style="font-size:1.5em;"><a href="mailto:kumar.ayush@iitkgp.ac.in" target="_top" f>kumar[dot]ayush[at]iitkgp[dot]ac[dot]in</a></span><br>
					<span style="font-size:1.5em;"><a href="mailto:k.ayush147@gmail.com" target="_top" f>k[dot]ayush147[at]gmail[dot]com</a></span><br><br>
                    <span style="font-size:1.5em;"><a href="mailto:k.ayush147@gmail.com" target="_top" f>kayush[at]adobe[dot]com</a></span><br><br>
					<span style="font-size:1.5em;">Phone:</span><br>				
					<span style="font-size:1.5em;"><a href="mailto:+91-8292878978" target="_top" f>+91-(91065^2+211^2+4^2+6^3) (India)</a></span> -->
					<span style="font-size:1.5em;">Email:</span>
                    <!-- <span style="font-size:1.5em;">k[dot]ayush147[at]gmail[dot]com</span><br> -->
                    <span style="font-size:1.5em;">kayush[at]adobe[dot]com</span><br><br>
					<span style="font-size:1.5em;">Mobile:</span><br>				
					<span style="font-size:1.5em;">+91-8292878978</span>
                </div>
                <div class="col-lg-4 col-lg-offset-4">
                    <br><br><br><br>
                    <div class="LI-profile-badge"  data-version="v1" data-size="large" data-locale="en_US" data-type="horizontal" data-theme="dark" data-vanity="kumar-ayush-a19534a5"><a class="LI-simple-link" href='https://www.linkedin.com/in/kumar-ayush-a19534a5'></a></div>
                </div>

            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="text-center">
        <div class="footer-above">
            <div class="container">
                <div class="row">
                    <div class="footer-col col-md-4">
                        <h3>Location</h3>
                        <p>Noida
                            <br>Uttar Pradesh, India</p>
                    </div>
                    <div class="footer-col col-md-4">
                        <h3>Find me at</h3>
                        <ul class="list-inline">
                            <li>
                                <a href="https://in.linkedin.com/in/kumar-ayush-a19534a5" target="_blank" class="btn-social btn-outline"><i class="fa fa-fw fa-linkedin"></i></a>
                            </li>
                            <li>
                                <a href="https://github.com/kayush95/" target="_blank" class="btn-social btn-outline"><i class="fa fa-fw fa-github"></i></a>
                            </li>                       
                            <li>
                                <a href="http://www.facebook.com/kumar.ayush.507" target="_blank" class="btn-social btn-outline"><i class="fa fa-fw fa-facebook"></i></a>
                            </li>
                            <li>
                                <a href="https://twitter.com/kmr_ayush" target="_blank" class="btn-social btn-outline"><i class="fa fa-fw fa-twitter"></i></a>
                            </li>
                        </ul>
                    </div>
                    <div class="footer-col col-md-4">
                        <h3>Design</h3>
                        <p>Freelance, a theme by <a href="http://startbootstrap.com">Start Bootstrap</a></p>
                    </div>
                </div>
            </div>
        </div>
        <div class="footer-below">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        Copyright &copy; Kumar Ayush 2019
                    </div>
                </div>
            </div>
        </div>
    </footer>

    <!-- Scroll to Top Button (Only visible on small and extra-small screen sizes) -->
    <div class="scroll-top page-scroll hidden-sm hidden-xs hidden-lg hidden-md">
        <a class="btn btn-primary" href="#page-top">
            <i class="fa fa-chevron-up"></i>
        </a>
    </div>

    <!-- Portfolio Modals -->
    <div class="portfolio-modal modal fade" id="proj1" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 col-lg-offset-0">
                        <div class="modal-body">
                            <h2>DeepFix: A Fully Convolutional Neural Network for predicting Human Eye Fixations</h2>
                            <hr class="star-primary">

                            <ul class="list-inline item-details" style="font-size:20px">
                                <li><i class="fa fa-tags"></i> Guide:
                                    <strong><a href="http://www.serc.iisc.ernet.in/~venky/" target="_blank" style="color:rgb(173, 45, 3)">Dr. R. Venkatesh Babu</a>
                                    </strong>
                                </li>
                                <li><i class="fa fa-tags"></i> Project Duration:
                                    <b style="color:rgb(173, 45, 3)">May 2015 - July 2015</b>
                                </li>
                                <li><i class="fa fa-tags"></i> Keywords:
                                    <b style="color:rgb(173, 45, 3)"> Computer Vision, Deep Learning</b>
                                </li>
                                <p><br><i class="fa fa-file-pdf-o"></i> <a href="http://ieeexplore.ieee.org/document/7937829/" target="_blank" style="color:blue">Publication</a></p>
                            </ul>

                                                      
							
							<p class="indent" style="text-align:justify">DeepFix</b><i> (Team VAL)</i> -- has been declared the <b>winner</b> of the <a href="http://lsun.cs.princeton.edu/2016/" target="_blank" style="color:rgb(173, 45, 3)">Large Scale Scene Understanding (LSUN) 2016</a> in <a href="http://lsun.cs.princeton.edu/leaderboard/index_2016.html" target="_blank" style="color:rgb(173, 45, 3)">Saliency Prediction</a>, organized by <b>Princeton University</b> in conjunction with <b>CVPR 2016</b>. The model is described in this <a href="http://ieeexplore.ieee.org/document/7937829/" target="_blank" style="color:rgb(173, 45, 3)">paper</a>.</p> 

							<p style="text-align:justify">This work has been accepted in <a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83" target="_blank" style="color:rgb(173, 45, 3)">IEEE Transactions on Image Processing 2017</a>.</p>
							
							<p class="indent" style="text-align:justify">Check out the performance of DeepFix on <a href="http://saliency.mit.edu/results_mit300.html" target="_blank" style="color:rgb(173, 45, 3)">MIT300</a> and <a href="http://saliency.mit.edu/results_cat2000.html" target="_blank" style="color:rgb(173, 45, 3)">CAT2000</a> datasets at<a href="http://saliency.mit.edu/home.html" target="_blank" style="color:rgb(173, 45, 3)"> MIT Saliency Benchmark</a>.</p> 

							<p class="indent" style="text-align:justify"><b>Abstract:</b> Understanding and predicting the human visual attentional mechanism is an active area of research in the fields of neuroscience and computer vision. In this work, we propose DeepFix, a fully convolutional neural network for accurate saliency prediction. Unlike classical works which characterize the saliency map using various hand-crafted features, our model automatically learns features in a hierarchical fashion and predicts saliency map in an end-to-end manner. DeepFix is designed to capture semantics at multiple scales while taking global context into account using network layers with very large receptive fields. Generally, fully convolutional nets are spatially invariant which prevents them from modeling location dependent patterns (e.g. centre-bias). Our network handles this by incorporating a novel Location Biased Convolutional layer. We evaluate our model on multiple challenging saliency datasets and show that it achieves state-of-the-art results.</p> 
						
							<br><br>
                            <!---<div style="margin:10px;">   
                                <figure>
                                    <img src="img/portfolio/DeepFixArchitecture.png" class="img-responsive img-centered" alt="" width="433" height="433">
                                    <figcaption style="margin:10px;">DeepFix Architecture</i>.</figcaption>
                                </figure>

                                <figure>
                                    <img src="img/portfolio/LBC.png" class="img-responsive img-centered" alt="" width="1200" >
                                    <figcaption style="margin:10px;">Location Biased Convolution Filter for learning location dependent patterns in data (e.g., centre-bias present in the eye-fixations).</figcaption>                  
                                </figure>

                            </div>--->
							<img src="img/portfolio/DeepFixArchitecture.png" class="img-responsive img-centered" alt="" width="433" height="433">
							<figcaption style="margin:10px;">Fig 1: DeepFix Architecture</i>.</figcaption>
							<br><br>
							<img src="img/portfolio/LBC.png" class="img-responsive img-centered" alt="">
							<figcaption style="margin:10px;">Fig 2: Location Biased Convolution Filter for learning location dependent patterns in data (e.g., centre-bias present in the eye-fixations).</figcaption> 
							<br><br><br><br>
							 
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>


    <div class="portfolio-modal modal fade" id="proj2" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 col-lg-offset-0">
                        <div class="modal-body">
                            <h2>OCR++: A Robust Framework For Information Extraction from Scholarly Articles</h2>
                            <hr class="star-primary">

                            <ul class="list-inline item-details" style="font-size:20px">
                                <li><i class="fa fa-tags"></i> Guide:
                                    <strong><a href="http://cse.iitkgp.ac.in/~pawang/" target="_blank" style="color:rgb(173, 45, 3)">Prof. Pawan Goyal</a>
                                    </strong> and
                                    <strong><a href="http://cse.iitkgp.ac.in/~animeshm/" target="_blank" style="color:rgb(173, 45, 3)">Prof. Animesh Mukherjee</a>
                                    </strong>
                                </li>
                                <li><i class="fa fa-tags"></i> Project Duration:
                                    <b style="color:rgb(173, 45, 3)">August 2015 - December 2015</b>
                                </li>
                                <li><i class="fa fa-tags"></i> Keywords:
                                    <b style="color:rgb(173, 45, 3)">Information Extraction, Machine Learning</b>
                                </li>
                                <p><br><i class="fa fa-file-pdf-o"></i> <a href="https://www.aclweb.org/anthology/C/C16/C16-1320.pdf" target="_blank" style="color:blue">Publication</a></p>
                            </ul>
                            
                           
							<img src="img/portfolio/ocr++.PNG" class="img-responsive img-centered" alt="" width="800"">
							<figcaption style="margin:10px;">Fig 1: Sub-tasks dependencies in OCR++.</figcaption> 

							<img src="img/new.png" style="width:50px;" align="left"><br><br><br>
							<p style="text-align:justify"><a href="http://www.cnergres.iitkgp.ac.in/OCR++/home/" target="_blank" style="color:rgb(173, 45, 3)">OCR++</a> has been selected for the prestigious <a href="http://gyti.techpedia.in/" target="_blank" style="color:rgb(173, 45, 3)">Gandhian Young Technological Innovation (GYTI) Award 2017</a> by <a href = "http://www.sristi.org/cms/" target="_blank" style="color:rgb(173, 45, 3)">SRISTI</a> (Society for Research and Initiatives for Sustainable Technologies and Institutions). These awards are given every year during the <b>Festival of Innovations (FOIN)</b> at the <b>Rashtrapati Bhawan (Office of the President of India)</b> in the month of March.</p>

                            <p style="text-align:justify">This <a href="https://www.aclweb.org/anthology/C/C16/C16-1320.pdf" target="_blank" style="color:rgb(173, 45, 3)">work</a> has been accepted to <a href="http://coling2016.anlp.jp/" target="_blank" style="color:rgb(173, 45, 3)">Coling 2016</a>.</p>
							
							<p class="indent" style="text-align:justify">OCR++ bagged the <b>third prize</b> at <a href="http://cse.iitkgp.ac.in/conf/IBM/" target="_blank" style="color:rgb(173, 45, 3)">IBM Day</a> 2016 (system demonstartion contest) at IIT Kharagpur.</p>

                            
							<p style="text-align:justify">OCR++ was also felicitated by <b>Flipkart</b> as the <b>best term project</b> of <b>Speech and Natural Language Processing</b> course in fall 2015.</p>
							
                            <p class="indent" style="text-align:justify"><b>Abstract:</b> This paper proposes OCR++, an open-source framework designed for a variety of information extraction tasks from scholarly articles including metadata (title, author names, affiliation and
                            e-mail), structure (section headings and body text, table and figure headings, URLs and footnotes) and bibliography (citation instances and references). We analyze a diverse set of scientific
                            articles written in English language to understand generic writing patterns and formulate rules
                            to  develop  this  hybrid  framework.   Extensive  evaluations  show  that  the  proposed  framework
                            outperforms the existing state-of-the-art tools with huge margin in structural information extraction along with improved performance in metadata and bibliography extraction tasks,  both in
                            terms of accuracy (around 50% improvement) and processing time (around 52% improvement).
                            A user experience study conducted with the help of 30 researchers reveals that the researchers
                            found this system to be very helpful. As an additional objective, we discuss two novel use cases
                            including automatically extracting links to public datasets from the proceedings, which would
                            further accelerate the advancement in digital libraries.  The result of the framework can be exported as a whole into structured TEI-encoded documents.  Our framework is accessible online
                            at <a href="http://www.cnergres.iitkgp.ac.in/OCR++/home/" target="_blank" style="color:rgb(173, 45, 3)">this URL</a>.</p> 

		

                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>


    <div class="portfolio-modal modal fade" id="proj3" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 col-lg-offset-0">
                        <div class="modal-body">
                            <h2>Augmented Reality for Marketing</h2>
                            <hr class="star-primary">

                            <ul class="list-inline item-details" style="font-size:20px">
                                <li><i class="fa fa-tags"></i> Guide:
                                    <strong><a href="https://research.adobe.com/person/gaurush-hiranandani/" target="_blank" style="color:rgb(173, 45, 3)">Gaurush Hiranandani</a>
                                    </strong> and
                                    <strong><a href="https://research.adobe.com/person/atanu-sinha/" target="_blank" style="color:rgb(173, 45, 3)">Dr. Atanu R Sinha</a>
                                    </strong>
                                </li>
                                <li><i class="fa fa-tags"></i> Project Duration:
                                    <b style="color:rgb(173, 45, 3)">May 2016 - July 2016</b>
                                </li>
                                <li><i class="fa fa-tags"></i> Keywords:
                                    <b style="color:rgb(173, 45, 3)">Augmented Reality, Recommendation, Targeting, Virtual-Commerce</b>
                                </li>
                                <!---<p><br><i class="fa fa-file-pdf-o"></i> <a href="pdfs/Kinect_Report.pdf" target="_blank" style="color:blue">Technical Report</a> | <i class="fa fa-picture-o"></i> <a href="pdfs/Kinect_Poster.pdf" target="_blank" style="color:blue">Poster</a></p> --->
                                <p><br><i class="fa fa-file-pdf-o"></i> <a href="http://ieeexplore.ieee.org/abstract/document/8088451/" target="_blank" style="color:blue">Publication</a></p>
                            </ul>
							
                            <br><br> 
                                <img src="img/portfolio/aug.PNG" class="img-responsive img-centered" alt="" width="600">
							<br>
                            <p class="indent" style="text-align:justify"><b>Abstract:</b> The trend of harnessing AR-based data has started breeding novel and enriching applications.  Though the AR-based apps have been
                            in existence for a long time, its true potential in digital marketing
                            domain has been not exploited yet. In this paper, we bridge this gap
                            through creating a novel consumer targeting system.  First, we an-
                            alyze interactions of consumer on AR-based retail apps to capture
                            rich AR interactions,  followed by identifying her purchase view-
                            point during the app session. We then target the consumer through
                            a personalized catalog, created by embedding recommended prod-
                            ucts in the viewpoint visual.  The color and style of the embedded
                            product is matched using the visual compatibility with the view-
                            point, and personalized text content is created using the visual cues
                            from the AR app data.  We then evaluate the system using exten-
                            sive user studies.  The results show that we are able to identify the
                            viewpoint, that our recommendations are better than the tag-based
                            content recommendation system.  Moreover, targeting through the
                            recommendations embedded in the viewpoint is significantly better
                            than the usual product catalog based targeting.</p> 

							<p class="indent" style="text-align:justify"><b>Three international patents</b> have been published.</p> 
							
							<p class="indent" style="text-align:justify">One of the patents was appreciated, by Adobe’s Patent Review Committee, as an important technology and has been filed in multiple countries.</p>

							-<p class="indent" style="text-align:justify">The work was also presented at <b>Adobe's Tech Summit 2017</b> in San Jose, California.</p>-

						<p class="indent" style="text-align:justify">This <a href="http://ieeexplore.ieee.org/abstract/document/8088451/" target="_blank" style="color:rgb(173, 45, 3)">work</a> has been accepted to <a href="https://ismar2017.sciencesconf.org/" target="_blank" style="color:rgb(173, 45, 3)">IEEE ISMAR 2017</a>.</p>
 
 
 
                          <div style="margin:10px;">  
                                <img src="img/portfolio/part1.jpg" class="img-responsive img-centered" alt="" width="1000">
                                <figcaption style="margin:10px;">Fig 1: System and Method to Identify Augmented Visuals Influencing Consumer Purchase in Virtual-Commerce.</figcaption>
                          </div>  
							<br><br><br><br>
                          <div style="margin:10px;">  
                                <img src="img/portfolio/part2.jpg" class="img-responsive img-centered" alt="" width="1000">
                                <figcaption style="margin:10px;">Fig 2: Product Recommendations Based on Augmented Reality Viewpoints.</figcaption>
                          </div>
							<br><br><br><br>
                          <div style="margin:10px;">  
                                <img src="img/portfolio/img1.PNG" class="img-responsive img-centered" alt="" width="600">
                                <figcaption style="margin:10px;">Fig 3: Product Recommendations from our model.</figcaption>
                          </div>						  
							<br><br><br><br>
                          <div style="margin:10px;">  
                                <img src="img/portfolio/part3.jpg" class="img-responsive img-centered" alt="" width="1000">
                                <figcaption style="margin:10px;">Fig 4: Viewpoint Driven Generation of Diversified Personalized Targeting Content.</figcaption>
                          </div>  						  
                                           

                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>


    <div class="portfolio-modal modal fade" id="proj4" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 col-lg-offset-0">
                        <div class="modal-body">
                            <h2>Combining Class Conditioned Representations in CNN for Salient Object Segmentation</h2>
                            <hr class="star-primary">

                            <ul class="list-inline item-details" style="font-size:20px">
                                <li><i class="fa fa-tags"></i> Guide:
                                    <strong><a href="http://www.serc.iisc.ernet.in/~venky/" target="_blank" style="color:rgb(173, 45, 3)">Dr. R. Venkatesh Babu</a>
                                    </strong>
                                </li>
                                <li><i class="fa fa-tags"></i> Project Duration:
                                    <b style="color:rgb(173, 45, 3)">May 2015 - July 2015</b>
                                </li>
                                <li><i class="fa fa-tags"></i> Keywords:
                                    <b style="color:rgb(173, 45, 3)">Computer Vision, Deep Learning</b>
                                </li>
                                <!---<p><br><i class="fa fa-file-pdf-o"></i> <a href="pdfs/Intel_Report.pdf" target="_blank" style="color:blue">Intern Report</a></p> --->
                            </ul>

                          

                            <p class="indent" style="text-align:justify">Worked on the development of a CNN framework followed by Dense Conditional Random Field (CRF) for Salient Object Segmentation. Proposed a deep fusion architecture which not only combines class-conditional representations but also introduces scale invariance by combining it via inception like module (inspired from GoogleNet). We evaluated our model on MSRA-1000 and CSSD datasets and were able to perform at par with state-of-the-art models.</p>

                            <!--- <div style="margin:10px;">   
                                <figure>
                                    <img src="img/projects/main/fall/system.jpg"  class="img-responsive img-centered" alt="" width="500" height="500">
                                </figure>

                                <figure>
                                    <img src="img/projects/main/fall/wearable.jpg" class="img-responsive img-centered" alt="" width="500" height="500">
                                </figure>

                            </div> ---->

						

                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>


    <div class="portfolio-modal modal fade" id="proj5" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 col-lg-offset-0" >
                        <div class="modal-body">
                            <h2>Supporting Throughput Fairness in IEEE 802.11ac Dynamic Bandwidth Channel Access: A Hybrid Approach</h2>
                            <hr class="star-primary">

                            <ul class="list-inline item-details" style="font-size:20px">
                                <li><i class="fa fa-tags"></i> Guide:
                                    <strong><a href="http://cse.iitkgp.ac.in/~sandipc/" target="_blank" style="color:rgb(173, 45, 3)">Prof. Sandip Chakraborty</a>
                                    </strong>
                                </li>
                                <li><i class="fa fa-tags"></i> Project Duration:
                                    <b style="color:rgb(173, 45, 3)">Dec 2016 - April 2017</b>
                                </li>
                                <li><i class="fa fa-tags"></i> Keywords: 
                                    <b style="color:rgb(173, 45, 3)"> Dynamic Bandwidth Channel Access, Throughput Fairness</b>
                                </li>
                                 <p><br><i class="fa fa-file-pdf-o"></i> <a href="http://ieeexplore.ieee.org/document/8109388/" target="_blank" style="color:blue">Publication</a></p>
                            </ul>

  


                            <p class="indent" style="text-align:justify"><b>Abstract:</b> Wi-Fi enabled hand-held devices have quickly occupied the consumer market as a result of the remarkable customer acceptance of IEEE 802.11 standard. In this regard, the demand of high throughput introduces high throughput standards such as IEEE 802.11ac. It supports <b>Dynamic Bandwidth Channel Access (DBCA)</b>>, where a wireless station selects channel bandwidth dynamically based on the availability of the secondary
							channels. But the widely-used contention based medium access mechanism provides an opportunistic access of secondary channels and affects the performance of DBCA. Consequently, unfairness in channel access is increased in DBCA, which further reduces average throughput of stations. In this paper, we develop a hybrid adaptive resource reservation mechanism, <b>Hybrid Adaptive DBCA (HA-DBCA)</b>, for supporting fair channel access in DBCA. In HA-DBCA, a polling based online learning mechanism is designed to avoid starvation of primary channel users. Through IEEE 802.11ac testbed implementation, we show that HA-DBCA improves throughput fairness in DBCA significantly along with other performance parameters. </p>

							<p class="indent" style="text-align:justify">This <a href="http://ieeexplore.ieee.org/document/8109388/" target="_blank" style="color:rgb(173, 45, 3)">work</a> has been published (oral paper) in <a href="http://www.ieeelcn.org/" target="_blank" style="color:rgb(173, 45, 3)">IEEE LCN 2017</a>.</p>

							<br><br><br><br>
                            <div style="margin:10px;">  
                                <img src="img/portfolio/DBCA2.png" class="img-responsive img-centered" alt="" width="800">
                                <figcaption style="margin:10px;">Fig 1: Unfairness in channel access in DBCA.</figcaption>
                            </div>
                            <br><br><br><br>
                            <div style="margin:10px;">  
                                <img src="img/portfolio/time.png" class="img-responsive img-centered" alt="">
                                <figcaption style="margin:10px;">Fig 2: Periodic DBCA and Contention Free (CF) Intervals in HA-DBCA.</figcaption>
                            </div>                     
                       
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>


    <div class="portfolio-modal modal fade" id="proj6" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 col-lg-offset-0">
                        <div class="modal-body">
                            <h2>Other Projects</h2>
                            <hr class="star-primary">

 <!--                            <ul class="list-inline item-details" style="font-size:20px">
                                <li><i class="fa fa-tags"></i> Guide:
                                    <strong><a href="http://www.nitt.edu/home/academics/departments/ice/faculty/bennet/" target="_blank" style="color:rgb(173, 45, 3)">Mr. Goldin R Bennet</a>
                                    </strong>
                                </li>
                                <li><i class="fa fa-tags"></i> Project Duration:
                                    <b style="color:rgb(173, 45, 3)">July - Nov 2016</b>
                                </li>
                                <li><i class="fa fa-tags"></i> Keywords: 
                                    <b style="color:rgb(173, 45, 3)">Embedded Systems, Computer Vision</b>
                                </li>
                                <p><br><i class="fa fa-file-pdf-o"></i> <a href="pdfs/Biometric_Report.pdf" target="_blank" style="color:blue">Project Report</a></p>
                            </ul> -->

            <ul>
				
                    <li class="indent" style="text-align:justify;font-size:25px;">Researcher Recommendation System</li>                
                        <p class="indent" style="text-align:justify"><b>Guide:</b> Prof. Pawan Goyal and Prof. Animesh Mukherjee<br>
                          Developed a search and recommendation engine for Scientific Research Community, as a part of Term Project
                          for the completion of Information Retrieval Course. Used beautiful soup and selenium in python to parse MAS
                          to generate the data set for the project (1 lakh authors and their publications). Used clustering techniques
                          to cluster similar authors based on their co-author graph to recommend new co-authors to an author. Used
                          LDA to model topics from the keyword database of an author and recommended top 100 authors based on
                          their rank (gained a 25% increase in recall). Further developed a full-fledged Scientific Search Engine.</p>
                    <br><br>     
                    <li class="indent" style="text-align:justify;font-size:25px;">TinyC Compiler</li>
                        <p class="indent" style="text-align:justify"><b>Guide:</b> Prof. Partha Pratim Das<br>
                          Designed and implemented a compiler for a C-like language (a subset of C language), as a part of Term Project
                          for the completion of Compilers Course.</p>
					<br><br>   
                    <!-- <li class="indent" style="text-align:justify;font-size:25px;">Image Deblurring using Convolutional Neural Networks</li>
                        <p class="indent" style="text-align:justify"><b>Guide:</b> Prof. Pabitra Mitra<br>
                          Implemented a deep convolutional neural network structure for image deconvolution. A series of convolution
                          steps were used for approximating deconvolution. The system uses two modules corresponding to deconvolution
                          and artifact removal.
                        </p>                           -->

            </ul>
							<!-- <p class="indent" style="text-align:justify">The product incorporates a two level security protocol - fingerprint authentication followed by Iris recognition. The entire process is streamlined via a simple graphical user interface. A compact fingerprint module registers unique fingerprints and a modified IR camera stores high resolution images. Potential customers can either enrol or authenticate themselves by following the on-screen instructions. The prototype adheres to a compact, modular design with ease of access for corresponding functions. All of the above is achieved at very nominals costs, given the materials and electronics we have chosen to work with – an optimal biometric solution.</p>

                            <div style="margin:10px;">  
                                <img src="img/projects/main/PDD/eye_match.png" class="img-responsive img-centered" alt="">
                                <figcaption style="margin:10px;">Image matching algorithm for iris data.</figcaption>
                            </div>  

 -->

                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>



    <div class="portfolio-modal modal fade" id="proj8" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 col-lg-offset-0">
                        <div class="modal-body">
                            <h2>Generative Adversarial Learning for Reducing Manual Annotation in Semantic Segmentation on Large Scale Microscopy Images</h2>
                            <hr class="star-primary">

                            <ul class="list-inline item-details" style="font-size:20px">
                                <li><i class="fa fa-tags"></i> Guide:
                                    <strong><a href="https://scholar.google.co.in/citations?user=5bXSZPYAAAAJ&hl=en" target="_blank" style="color:rgb(173, 45, 3)">Prof. Pabitra Mitra</a>
                                    </strong>
                                </li>
                                <li><i class="fa fa-tags"></i> Project Duration:
                                    <b style="color:rgb(173, 45, 3)">Dec 2016 - April 2017</b>
                                </li>
                                <li><i class="fa fa-tags"></i> Keywords:
                                    <b style="color:rgb(173, 45, 3)">Machine Learning, Computer Vision</b>
                                </li>
                                <p><br><i class="fa fa-file-pdf-o"></i> <a href="http://openaccess.thecvf.com/content_cvpr_2017_workshops/w8/papers/Lahiri_Generative_Adversarial_Learning_CVPR_2017_paper.pdf" target="_blank" style="color:blue">Publication</a></p>

                            </ul>

                           
                           	<p style="text-align:justify">This work has been accepted in the<a href="http://cvmi2017.cs.rutgers.edu/Welcome/indexWelcome.html" target="_blank" style="color:rgb(173, 45, 3)"> Workshop on Computer Vision for Microscopy Image Analysis (CVMI) at CVPR 2017</a>. This work was part of my thesis which received the <b>Best Bachelor's Thesis Award</b> in the Department of Computer Science and Engineering, IIT Kharagpur.</p>

                          

                            <p style="text-align:justify"><b>Abstract:</b> Convolutional Neural Network(CNN) based semantic
							segmentation require extensive pixel level manual annotation which is daunting for large microscopic images.
							The paper is aimed towards mitigating this labeling effort
							by leveraging the recent concept of generative adversarial network(GAN) wherein a generator maps latent noise
							space to realistic images while a discriminator differentiates between samples drawn from database and generator.
							We extend this concept to a multi task learning wherein
							a discriminator-classifier network differentiates between
							fake/real examples and also assigns correct class labels.
							Though our concept is generic, we applied it for the challenging task of vessel segmentation in fundus images. We
							show that proposed method is more data efficient than a
							CNN. Specifically, with 150K, 30K and 15K training examples, proposed method achieves mean AUC of 0.962, 0.945
							and 0.931 respectively, whereas the simple CNN achieves
							AUC of 0.960, 0.921 and 0.916 respectively.</p>

							<!-- <p style="text-align:justify">Currently working towards a journal submission.</p> -->

							<div style="margin:10px;">  
                                <img src="img/portfolio/retina_gan.png" class="img-responsive img-centered" alt="" width="500">
                                <figcaption style="margin:10px;">Fig 1: Proposed model for GAN based semantic segmentation on fundus images.</figcaption>
                          	</div>  
                        

                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div class="portfolio-modal modal fade" id="proj7" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 col-lg-offset-0">
                        <div class="modal-body">
                            <h2>Semi-Supervised Learning with Generative Adversarial Networks for Action Recognition in Images</h2>
                            <hr class="star-primary">

                            <ul class="list-inline item-details" style="font-size:20px">
                                <li><i class="fa fa-tags"></i> Guide:
                                    <strong><a href="https://scholar.google.co.in/citations?user=5bXSZPYAAAAJ&hl=en" target="_blank" style="color:rgb(173, 45, 3)">Prof. Pabitra Mitra</a>
                                    </strong>
                                </li>
                                <li><i class="fa fa-tags"></i> Project Duration:
                                    <b style="color:rgb(173, 45, 3)">Oct 2016 - Present</b>
                                </li>
                                <li><i class="fa fa-tags"></i> Keywords:
                                    <b style="color:rgb(173, 45, 3)">Machine Learning, Computer Vision</b>
                                </li>
                                
                            </ul>

                          
                            
                            <p style="text-align:justify">Visual recognition of human-object interactions in images is a prerequisite for generating image descriptions and retrieving images by sentences. A key bottleneck to recognition of such interactions is the categories that have very few training examples. 
		                    In such cases, semantic knowledge can significantly improve recognition.
		                    A rare category might piggyback on a co-occurring interaction that has more training data thus resulting in an improved recognition. 
		                    In this work, I seek to study whether GANs can be used in a semi-supervised setting for recognition of human-object interactions in images, which is an important subset of the larger problem of action recognition. 
		                    We intend to delve deeper and extend the work to videos as well.</p>  
                          

                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div class="portfolio-modal modal fade" id="exp1" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 col-lg-offset-0">
                        <div class="modal-body">
                            <iframe width="853" height="480" src="https://www.youtube.com/embed/-D7WXVTPXuo?rel=0" frameborder="0" allowfullscreen></iframe>


                            <p style="text-align:justify"><br>In the summer of 2016, I was fortunate enough to be selected for the <a href="http://riss.ri.cmu.edu/" target="_blank" style="color:blue">Robotics Institute Summer Scholars (RISS) Program</a> at the <a href="https://www.ri.cmu.edu/" target="_blank" style="color:blue">Carnegie Mellon Robotics Institute</a>. I was one of the 36 undergraduate researchers from across the world to be given this opportunity. I was awarded a fellowship from the <a href="http://iusstf.org/story/53-74-For-Indian-Students.html" target="_blank" style="color:blue">S. N. Bose Scholarship</a> and IUSSTF to pursue this 11-week internship.</p>

                            <div style="padding-top:20px;padding-bottom: 20px">   
                                <figure>
                                    <img src="img/Interns/cmu/lab.jpg" class="img-responsive img-centered" alt="" width="415">
                                </figure>

                                <figure>
                                    <img src="img/Interns/cmu/me.jpg" class="img-responsive img-centered" alt="" width="400">
                                </figure>
                            </div>

                            <p style="text-align:justify">I was guided by <a href="http://www.ri.cmu.edu/person.html?person_id=339" target="_blank" style="color:blue">Dr. William L. “Red” Whittaker</a>, a pioneer in field robotics. I worked in a spin-off of the <a href="http://www.frc.ri.cmu.edu/" target="_blank" style="color:blue">Field Robotics Center</a> (FRC), the Planetary Robotics Lab. The lab is in pursuit of the <a href="http://lunar.xprize.org/" target="_blank" style="color:blue">Google Lunar X Prize</a>, which aims to land a rover on the moon. The project I was working on was in the field of vision and kinematics, a method to estimate 10 DoF of a rover using simply an omnidirectional camera.</p>

                            <div style="padding-top:20px;padding-bottom: 20px">   
                                <figure>
                                    <img src="img/Interns/cmu/field_test.jpg" class="img-responsive img-centered" alt="" width="415">
                                </figure>

                                <figure>
                                    <img src="img/Interns/cmu/robot_city.jpg" class="img-responsive img-centered" alt="" width="500">
                                </figure>
                            </div>

                            <p style="text-align:justify">Over my stay at CMU, I gained exposure to various fields of robotics via seminars, talks and informal discussions. The FRC is at the forefront of developing systems that intuitively perceive their environments, with faculty most active in ground and aerial robotics. The RISS program consisted of a ROS workshop, a trip to the <a href="http://www.nrec.ri.cmu.edu/" target="_blank" style="color:blue">National Robotics Engineering Center</a> and tutorials for communication and research presentation.</p>

                            <p style="text-align:justify">As a summer scholar, I participated actively in planning cohort activities. I was also a peer editor for the <a href="http://riss.ri.cmu.edu/journals/" target="_blank" style="color:blue">RISS Working Papers Journal</a>, which presents the cohort’s summer contributions. The summer culminated with a research showcase, where scholars presented their work through a poster session.</p>

                            <img src="img/Interns/cmu/prez.jpg" class="img-responsive img-centered" alt="" width="500" height="500">

                            <p style="text-align:justify">You can read more about my summer in a short piece I wrote for my college magazine <a href="https://issuu.com/feeds.nitt/docs/volume_6.0_issue_01/10" target="_blank" style="color:red">here</a>. To learn about my project, visit the projects section.</p>

                        </div>
                        <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>

                    </div>
                </div>
            </div>
        </div>
    </div>

    <div class="portfolio-modal modal fade" id="exp2" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 col-lg-offset-0">
                        <div class="modal-body">


                        <div style="padding-top:20px;padding-bottom: 20px">   
                            <figure>
                                <img src="img/Interns/iisc/iisc.jpg" class="img-responsive img-centered" alt="" width="415">
                            </figure>

                            <figure>
                                <img src="img/Interns/iisc/VAL_logo.png" class="img-responsive img-centered" alt="" width="340">
                            </figure>
                        </div>

                        <p style="text-align:justify">In 2015, I was a summer intern at the <a href="http://www.iisc.ac.in/" target="_blank" style="color:blue">Indian Institute of Science</a>. Here, I worked under <a href="http://www.serc.iisc.ernet.in/~venky/" target="_blank" style="color:blue">Dr. R. Venkatesh Babu</a> of the <a href="http://val.serc.iisc.ernet.in/valweb/index.html" target="_blank" style="color:blue">Video Analytics Lab</a> (VAL). The VAL is dedicated to problems spanning the domains of signal processing, compression, machine vision, image/video processing, pattern recognition and multimedia. It is a research group of the <a href="cds.iisc.in" target="_blank" style="color:blue">Department of Computational and Data Sciences</a>, and works extensively with deep learning and neural networks.</p>

                        <img style="padding-top:20px;padding-bottom: 20px" src="img/Interns/iisc/expt.jpg" class="img-responsive img-centered" alt="" width="600" height="600">

                        <p style="text-align:justify">I worked on a project in image saliency and understanding for sparse sketches, with <a href="http://cds.iisc.ac.in/student/ravikiran" target="_blank" style="color:blue">Ravi Kiran Sarvadevabhatla</a> for the period of 2 months. The results of this exploration have been submitted to a top-tier image processing journal.</p>

                        <p style="text-align:justify">To read more on this, visit the projects section.</p>

                        </div>
                        <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>

                    </div>
                </div>
            </div>
        </div>
    </div>

    <div class="portfolio-modal modal fade" id="exp3" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 col-lg-offset-0">
                        <div class="modal-body">


                        <div style="padding-top:20px;padding-bottom: 20px">   
                            <figure>
                                <img src="img/Interns/intel/ece_dept.jpg" class="img-responsive img-centered" alt="" width="500">
                            </figure>

                            <figure>
                                <img src="img/Interns/intel/intel_edu.jpg" class="img-responsive img-centered" alt="" width="440">
                            </figure>
                        </div>

                        <p style="text-align:justify">In the winter of 2014, I was selected for an Intel Internship on campus, organized by the Electronics and Communication Department of NIT Trichy. It was an opportunity to develop solutions for real-world problems, harnessing the potential of the Internet-of-Things. Working under <a href="http://www.nitt.edu/home/academics/departments/ece/faculty/bvenki/" target="_blank" style="color:blue">Dr. B. Venkataramani</a>, I designed a wearable fall-detection monitor on an IoT platform. I built, tested and validated the system over the course of the 1 month intern.</p>

                        <p style="text-align:justify">For further reading, visit the projects section.</p>

                        </div>
                        <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>

                    </div>
                </div>
            </div>
        </div>
    </div>


    <!-- jQuery -->
    <script src="vendor/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Theme JavaScript -->
    <script src="js/freelancer.min.js"></script>

</body>

</html>
